[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this blog"
  },
  {
    "objectID": "welcome/TEMPO.html",
    "href": "welcome/TEMPO.html",
    "title": "SPOTIFY TOP 50",
    "section": "",
    "text": "Logowik\n\n\nWhile it’s often highlighted how musical styles evolve over time, certain elements like tempo show remarkable consistency, especially in popular music. Despite the evolution of genres and production techniques, the tempo of popular music has maintained a certain uniformity across different eras. Below, we explore such consistencies in contemporary music.\n\nimport pandas as pd\n\n# Load the dataset\nspotify_df_global = pd.read_csv('Spotify_Global_Top50_Audio_Features.csv')\n\n# Calculate the 95th and 99th percentile values for Popularity\npercentile_95 = spotify_df_global['Popularity'].quantile(0.95)\npercentile_99 = spotify_df_global['Popularity'].quantile(0.99)\n\n# Filter the dataset to include only the rows within the 95th to 99th percentile\nfiltered_data = spotify_df_global[(spotify_df_global['Popularity'] &gt;= percentile_95) & (spotify_df_global['Popularity'] &lt;= percentile_99)]\n\n# Define the feature columns for which to calculate the mean\nfeature_columns = ['danceability', 'energy', 'valence', 'tempo']\n\n# Calculate the mean of each feature within the filtered data\nmean_scores = filtered_data[feature_columns].mean()\n\nprint(\"Mean Scores of Features in the 95th to 99th Percentile of Popularity:\")\nprint(mean_scores)\n\nMean Scores of Features in the 95th to 99th Percentile of Popularity:\ndanceability      0.705667\nenergy            0.617667\nvalence           0.569000\ntempo           105.339333\ndtype: float64\n\n\n\nimport pandas as pd\n\nspotify_df_global = pd.read_csv('Spotify_Global_Top50_Audio_Features.csv')\n\nbottom_scores_global = spotify_df_global[spotify_df_global['Popularity'].between(70,80)]\n\nfeature_columns = ['danceability', 'energy', 'valence', 'tempo']  # Adjust if needed\n\nprint(bottom_scores_global[[ 'Popularity'] + feature_columns])\n\n    Popularity  danceability  energy  valence    tempo\n26          77         0.599   0.946    0.747  151.647\n31          78         0.464   0.745    0.262  180.098\n\n\n\nspotify_df_2000 = pd.read_csv('Spotify-2000.csv')\nspotify_df_median = spotify_df_2000[['Danceability', 'Energy', 'Valence', 'Beats Per Minute (BPM)']].median()\nprint(spotify_df_median)\n\nspotify_df_global_median = spotify_df_global[['danceability', 'energy', 'valence', 'tempo']].median()\nprint(spotify_df_global_median)\n\nDanceability               53.0\nEnergy                     61.0\nValence                    47.0\nBeats Per Minute (BPM)    119.0\ndtype: float64\ndanceability      0.664\nenergy            0.637\nvalence           0.569\ntempo           120.026\ndtype: float64\n\n\n\nimport pandas as pd\n\n# Load the datasets\nspotify_df_2000 = pd.read_csv('Spotify-2000.csv')\nspotify_df_global = pd.read_csv('Spotify_Global_Top50_Audio_Features.csv')\n\n  \n# Scale up the normalized median values for Danceability, Energy, and Valence\nscaled_median_2000s = spotify_df_median[['Danceability', 'Energy', 'Valence']] * 1  # Multiply by 100 to match the original scale\n\n# Ensure that the Top 50 Median Scores are correctly scaled for consistency (excluding Tempo)\nscaled_median_top50 = spotify_df_global_median[['danceability', 'energy', 'valence']] * 100\n\n# Add Tempo back to the DataFrame without scaling\nscaled_median_2000s['Tempo'] = spotify_df_median['Beats Per Minute (BPM)']\nscaled_median_top50['Tempo'] = spotify_df_global_median['tempo']\n\n# Create a DataFrame to compare the scaled medians\ncomparison_df = pd.DataFrame({\n    '2000s Median Scores': scaled_median_2000s.values,\n    'Top 50 Median Scores': scaled_median_top50.values\n})\n\n# Adjust index to match the features' names\ncomparison_df.index = ['Danceability', 'Energy', 'Valence', 'Tempo']\n\n# Display the comparison\nprint(comparison_df)\n\n              2000s Median Scores  Top 50 Median Scores\nDanceability                 53.0                66.400\nEnergy                       61.0                63.700\nValence                      47.0                56.900\nTempo                       119.0               120.026\n\n\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\ncomparison_df = pd.DataFrame({\n    '2000s Median Scores': scaled_median_2000s.values,\n    'Top 50 Median Scores': scaled_median_top50.values\n})\ncomparison_df.index = ['Danceability', 'Energy', 'Valence', 'Tempo']\n\n# Plotting the comparison\nplt.figure(figsize=(10, 6))\ncomparison_df.plot(kind='bar', color=['skyblue', 'green'], edgecolor='black')\n\nplt.title('Comparison of Median Audio Features: 2000s vs Top 50 Global Songs')\nplt.xlabel('Audio Features')\nplt.ylabel('Median Scores')\nplt.xticks(rotation=0)\nplt.ylim(0, max(comparison_df.max()) + 20)  # Set y-axis limit slightly above the maximum value\nplt.grid(axis='y')\n\nplt.show()\n\n&lt;Figure size 1000x600 with 0 Axes&gt;\n\n\n\n\n\n\n\n\n\n\n\nspotify_df_2000 = pd.read_csv('Spotify-2000.csv')\nspotify_df_global = pd.read_csv('Spotify_Global_Top50_Audio_Features.csv')\n\n# Calculate the mean for each feature in the Spotify 2000 dataset\nmean_2000s = spotify_df_2000[['Danceability', 'Energy', 'Valence', 'Beats Per Minute (BPM)']].mean()\n\n# Calculate the mean for each feature in the Top 50 Global dataset\nmean_top50 = spotify_df_global[['danceability', 'energy', 'valence', 'tempo']].mean()\n\n# Scale only 'danceability', 'energy', and 'valence' but not 'tempo'\nscaled_mean_top50 = mean_top50.copy()\nscaled_mean_top50[['danceability', 'energy', 'valence']] *= 100\n\n# Create a DataFrame to compare the means\nmean_comparison_df = pd.DataFrame({\n    '2000s Mean Scores': mean_2000s.values,\n    'Top 50 Mean Scores': scaled_mean_top50.values\n})\n\n# Adjust index to match the features' names\nmean_comparison_df.index = ['Danceability', 'Energy', 'Valence', 'Tempo']\n\n# Display the comparison DataFrame\nprint(mean_comparison_df)\n# Adjust index to match the features' names\nmean_comparison_df.index = ['Danceability', 'Energy', 'Valence', 'Tempo']\n\n# Plotting the comparison\nplt.figure(figsize=(10, 6))\nmean_comparison_df.plot(kind='bar', color=['lightblue', 'green'], edgecolor='black')\n\nplt.title('Comparison of Mean Audio Features: 2000s vs Top 50 Global Songs')\nplt.xlabel('Audio Features')\nplt.ylabel('Mean Scores')\nplt.xticks(rotation=0)\nplt.ylim(0, 130)  # Set y-axis limit to 120\nplt.grid(axis='y')\n\nplt.show()\n\n              2000s Mean Scores  Top 50 Mean Scores\nDanceability          53.238215            66.30200\nEnergy                59.679539            64.13000\nValence               49.408726            56.15160\nTempo                120.215647           123.91218\n\n\n&lt;Figure size 1000x600 with 0 Axes&gt;\n\n\n\n\n\n\n\n\n\nThe bar charts highlight differences in median and mean scores for Danceability, Energy, Valence, and Tempo.\nThis bar chart vividly illustrates the tempo variations among these top tracks, which do not vary widely, suggesting a consistency in tempo among the most popular songs globally.\n\ntop50_df = pd.read_csv('Spotify_Global_Top50_Audio_Features.csv')\n\n# Extract the top 10 songs based on popularity\ntop_10_songs = top50_df.nlargest(5, 'Popularity')\n\nplt.figure(figsize=(12, 6))\n\n# Bar plot for BPM\nsns.barplot(x=top_10_songs['Track Name'], y=top_10_songs['tempo'])\n\nplt.title('BPM of Top 10 Songs in Global Top 50')\nplt.xlabel('Track Name')\nplt.ylabel('Beats Per Minute (BPM)')\nplt.xticks(rotation=45, ha='right')\n\nplt.show()\n\n\n\n\n\n\n\n\nThese two figures were created after extracting the top 5 songs from both datasets. Despite the variability present for the larger dataset, it is imperative to observe that trends point to higher BPMs being prioritized across datasets.\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nspotify_df = pd.read_csv('Spotify-2000.csv')\n\n# Extract the top 10 songs based on popularity\ntop_10_songs =spotify_df.nlargest(5, 'Popularity')\n\n# Create a plot\nplt.figure(figsize=(12, 6))\n\n# Bar plot for BPM\nsns.barplot(x=top_10_songs['Title'], y=top_10_songs['Beats Per Minute (BPM)'])\n\n\n# Adding titles and labels\nplt.xlabel('Track Name')\nplt.ylabel('Beats Per Minute (BPM)')\nplt.xticks(rotation=50, ha='right')\n\nplt.show()\n\n\n\n\n\n\n\n\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nspotify_df_2000 = pd.read_csv('Spotify-2000.csv')\n\n# Plot the distribution of BPM in the 2000s dataset\nplt.figure(figsize=(10, 6))\nsns.histplot(spotify_df_2000['Beats Per Minute (BPM)'], bins=30, kde=True, color='blue')\n\n# Adding titles and labels\nplt.title('Distribution of BPM in the 2000s Dataset')\nplt.xlabel('Beats Per Minute (BPM)')\nplt.ylabel('Frequency')\n\n# Display the plot\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n# Histogram to visualize the distribution of BPM\nplt.figure(figsize=(10, 6))\nsns.histplot(top50_df['tempo'], bins=30, kde=True)\nplt.title('BPM Distribution in Global Top 50')\nplt.xlabel('BPM')\nplt.ylabel('Frequency')\nplt.grid(True)\nplt.show()\n\n# Analyzing common BPM peaks\nbpm_peaks = top50_df['tempo'].value_counts().sort_values(ascending=False)\nprint(bpm_peaks.head(10))\n\n\n\n\n\n\n\n\ntempo\n116.034    1\n104.978    1\n103.969    1\n107.071    1\n116.712    1\n128.027    1\n101.061    1\n99.986     1\n105.029    1\n80.969     1\nName: count, dtype: int64\n\n\nConversely, distributions were generated for all music available in both datasets, in effortds to visualize which particularly tempos produced the most success. Given that both datasets already depict popular music, it is evident that most songs cluster among the 100-140 tempo."
  },
  {
    "objectID": "posts/Project.html",
    "href": "posts/Project.html",
    "title": "Spotify Audio Feature Analysis:",
    "section": "",
    "text": "Research Motivation:\nThis analysis provides an exciting opportunity to delve into the evolution of popular music and identify the characteristics that contribute to a song’s success. This analysis offers a compelling opportunity to examine the evolution of musical characteristics and their relationship with popularity over several decades. The insights derived from this analysis will not only enhance our understanding of the trajectory of popular music but also provide valuable context for anticipating future trends in the music landscape.\nResearch Questions:\nThis research seeks to address several critical questions:\nWhat characteristics are common among the most popular songs?\nHow have trends in music shifted over time?\nAre there specific artists or genres that consistently produce top hits?\nTo what extent can popularity be predicted based on these characteristics?\nData Overview:\nThe analysis draws upon two distinct datasets that offer a comprehensive view of both historical and contemporary music trends.\nThe primary dataset, Spotify - All Time Top 2000s Mega Dataset, comprises the top 2000 tracks on Spotify, spanning releases from 1956 to 2019. This dataset features tracks from iconic artists such as Queen, The Beatles, and Guns N’ Roses, and includes a rich array of audio features that provide a deep dive into the characteristics that have defined popular music over the last 60 years.\nTo complement the historical analysis, a secondary dataset was extracted using the Spotify API, capturing audio features for the top 50 songs currently trending globally on Spotify. This real-time dataset offers a snapshot of contemporary musical preferences, serving as a critical point of comparison to assess how current trends align or diverge from those observed in previous decades.\nFeature Descriptions\nBoth datasets encompass a set of key features essential for this analysis:\nArtist: The performer of the track.\nTop Genre: The genre classification of the track.\nYear: The release year of the track.\nBeats per Minute (BPM): The tempo of the song.\nEnergy: A measure of the track’s intensity and activity.\nDanceability: Indicates the suitability of the song for dancing.\nLoudness: The volume level of the track.\nValence: Reflects the positivity of the song’s mood.\nLength: The duration of the track.\nAcousticness: The degree to which the song is acoustic.\nSpeechiness: The amount of spoken word content in the song.\nPopularity: A measure of the song’s popularity on Spotify."
  },
  {
    "objectID": "posts/Project.html#a-comparative-analysis-of-top-2000s-global-top-5-and-notable-artists",
    "href": "posts/Project.html#a-comparative-analysis-of-top-2000s-global-top-5-and-notable-artists",
    "title": "Spotify Audio Feature Analysis:",
    "section": "",
    "text": "Research Motivation:\nThis analysis provides an exciting opportunity to delve into the evolution of popular music and identify the characteristics that contribute to a song’s success. This analysis offers a compelling opportunity to examine the evolution of musical characteristics and their relationship with popularity over several decades. The insights derived from this analysis will not only enhance our understanding of the trajectory of popular music but also provide valuable context for anticipating future trends in the music landscape.\nResearch Questions:\nThis research seeks to address several critical questions:\nWhat characteristics are common among the most popular songs?\nHow have trends in music shifted over time?\nAre there specific artists or genres that consistently produce top hits?\nTo what extent can popularity be predicted based on these characteristics?\nData Overview:\nThe analysis draws upon two distinct datasets that offer a comprehensive view of both historical and contemporary music trends.\nThe primary dataset, Spotify - All Time Top 2000s Mega Dataset, comprises the top 2000 tracks on Spotify, spanning releases from 1956 to 2019. This dataset features tracks from iconic artists such as Queen, The Beatles, and Guns N’ Roses, and includes a rich array of audio features that provide a deep dive into the characteristics that have defined popular music over the last 60 years.\nTo complement the historical analysis, a secondary dataset was extracted using the Spotify API, capturing audio features for the top 50 songs currently trending globally on Spotify. This real-time dataset offers a snapshot of contemporary musical preferences, serving as a critical point of comparison to assess how current trends align or diverge from those observed in previous decades.\nFeature Descriptions\nBoth datasets encompass a set of key features essential for this analysis:\nArtist: The performer of the track.\nTop Genre: The genre classification of the track.\nYear: The release year of the track.\nBeats per Minute (BPM): The tempo of the song.\nEnergy: A measure of the track’s intensity and activity.\nDanceability: Indicates the suitability of the song for dancing.\nLoudness: The volume level of the track.\nValence: Reflects the positivity of the song’s mood.\nLength: The duration of the track.\nAcousticness: The degree to which the song is acoustic.\nSpeechiness: The amount of spoken word content in the song.\nPopularity: A measure of the song’s popularity on Spotify."
  },
  {
    "objectID": "welcome/artist.html",
    "href": "welcome/artist.html",
    "title": "My Blog",
    "section": "",
    "text": "Artists & Tempo\n\nPrevious analysis revealed that the mean tempos from the 2000s and 2024 datasets are 120.22 BPM and 123.91 BPM, respectively. This slight increase does not significantly alter the perception of tempo, suggesting a general stability in the beats per minute that define popular tracks across nearly two and a half decades.\n\nUtilizing the Spotify API, further analysis was conducted on the audio features of top tracks from iconic artists such as Taylor Swift and Coldplay. Focusing on artists who span these periods, such as Coldplay and Taylor Swift, we see a consistency in their use of tempo. Coldplay’s music, known for its anthemic quality, has maintained a steady tempo close to the average of popular music from the early 2000s, echoing a traditional rock influence. Similarly, Taylor Swift, despite her genre crossovers, has shown remarkable consistency in the tempo of her hits, with only marginal variations to adapt to modern pop and electronic influences.\n\n\nimport spotipy\nfrom spotipy.oauth2 import SpotifyClientCredentials\nimport numpy as np \n\n\n# Set up your credentials\nclient_id = '65da108bf5264338923828f386e46acd'\nclient_secret = '12fa81f51ba54420b18eedd354575dc4'\n\n# Authenticate with Spotify\nclient_credentials_manager = SpotifyClientCredentials(client_id=client_id, client_secret=client_secret)\nsp = spotipy.Spotify(client_credentials_manager=client_credentials_manager)\n\n# Taylor Swift's Spotify artist ID\n\ntaylor_swift_id = \"06HL4z0CvFAxyc27GXpf02\"\n\n# Get artist details\ndef get_artist_info(artist_id):\n    artist = sp.artist(artist_id)\n    return artist\n\n# Function to get top tracks for an artist\ndef get_top_tracks(artist_id, limit=50):\n    results = sp.artist_top_tracks(artist_id)\n    tracks = results['tracks'][:limit]\n    return [track['id'] for track in tracks]\n\n# Function to get audio features for multiple tracks\ndef get_audio_features(track_ids):\n    features = sp.audio_features(track_ids)\n    return features\n\n# Analyze audio features across top tracks\ntrack_ids = get_top_tracks(taylor_swift_id, limit=50)\nfeatures = get_audio_features(track_ids)\n\n# Calculate the average of each audio feature\ndef average_features(features):\n    feature_keys = ['danceability', 'energy', 'valence', 'tempo']\n    averages = {}\n    for key in feature_keys:\n        averages[key] = np.mean([feature[key] for feature in features if feature])\n    return averages\n\n# Get and print average features\naverage_audio_features = average_features(features)\nprint(\"Average Audio Features for Taylor Swift's Top 50 Tracks:\")\nfor feature, value in average_audio_features.items():\n    print(f\"{feature.capitalize()}: {value:.2f}\")\naverage_tempo_taylor = np.mean([feature['tempo'] for feature in features if feature])\n\nAverage Audio Features for Taylor Swift's Top 50 Tracks:\nDanceability: 0.57\nEnergy: 0.54\nValence: 0.39\nTempo: 125.19\n\n\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Load datasets\nspotify_df_2000 = pd.read_csv('Spotify-2000.csv')\ntop50_df = pd.read_csv('Spotify_Global_Top50_Audio_Features.csv')\n\n# Calculate average tempo for the Spotify 2000s dataset\naverage_tempo_2000s = spotify_df_2000['Beats Per Minute (BPM)'].mean()\n\n# Calculate average tempo for the Global Top 50 dataset\naverage_tempo_top50 = top50_df['tempo'].mean()\n\n\n# Combine the average tempo values into a DataFrame\ntempo_comparison_df = pd.DataFrame({\n    'Taylor Swift': [average_tempo_taylor],\n    '2000s Dataset': [average_tempo_2000s],\n    'Global Top 50': [average_tempo_top50]\n})\n\n# Plot the comparison\ntempo_comparison_df.plot(kind='bar', figsize=(10, 6))\n\n# Add title and labels\nplt.title('Comparison of Average Tempo (BPM)')\nplt.ylabel('Beats Per Minute (BPM)')\nplt.xticks(rotation=0)\nplt.legend(loc='upper right')\nplt.grid(axis='y')\n\n# Show the plot\nplt.show()\n\n\n\n\n\n\n\n\n\n# Function to get audio features for multiple tracks\ndef get_audio_features(track_ids):\n    features = sp.audio_features(track_ids)\n    return features\n\n# Analyze audio features across top tracks\nfeatures = get_audio_features(track_ids)\n\n# Extract tempo information\ncoldplay_tempos = [track['tempo'] for track in features if track]\n\n# Calculate the average tempo\naverage_tempo_coldplay = np.mean(coldplay_tempos)\n\nprint(f\"Average Tempo for Coldplay's Top 50 Tracks: {average_tempo_coldplay:.2f} BPM\")\n\nAverage Tempo for Coldplay's Top 50 Tracks: 125.19 BPM\n\n\n\n# Load the 2000s and Top 50 datasets\nspotify_df_2000 = pd.read_csv('Spotify-2000.csv')\ntop50_df = pd.read_csv('Spotify_Global_Top50_Audio_Features.csv')\n\n# Calculate the average tempo for the 2000s dataset\naverage_tempo_2000s = spotify_df_2000['Beats Per Minute (BPM)'].mean()\n\n# Calculate the average tempo for the Top 50 Global dataset\naverage_tempo_top50 = top50_df['tempo'].mean()\n\n# Create a DataFrame to compare the averages\ntempo_comparison_df = pd.DataFrame({\n    'Dataset': ['Coldplay', '2000s', 'Global Top 50'],\n    'Average Tempo (BPM)': [average_tempo_coldplay, average_tempo_2000s, average_tempo_top50]\n})\n\n# Display the DataFrame\nprint(tempo_comparison_df)\n\n         Dataset  Average Tempo (BPM)\n0       Coldplay           125.192100\n1          2000s           120.215647\n2  Global Top 50           123.912180\n\n\n\n# Plot the average tempos\nplt.figure(figsize=(10, 6))\nsns.barplot(x='Dataset', y='Average Tempo (BPM)', data=tempo_comparison_df)\n\n# Adding titles and labels\nplt.title('Average Tempo Comparison: Coldplay vs 2000s vs Global Top 50')\nplt.xlabel('Dataset')\nplt.ylabel('Average Tempo (BPM)')\nplt.show()\n\n\n\n\n\n\n\n\n\nThe results underscore Coldplay’s consistent preference for moderate tempos compared to industry trends, while Taylor Swift exhibited a broad range of tempos across her discography, still remaining within the average tempo found in most other popular songs. Evidently, across different genres and, despite fluctuating audio features like danceability and valence, these artists seem to consistently adhere to their tempo parameters of ~120bpm."
  },
  {
    "objectID": "welcome/index.html",
    "href": "welcome/index.html",
    "title": "Findings, final note",
    "section": "",
    "text": "This brief analysis furthers an intriguing aspect of musical evolution—the consistency of tempo. While genres may shift and new technologies might change the way music is produced and consumed, the tempo of popular music has shown remarkable stability. This consistency across decades not only underscores the intrinsic qualities of tempo in music but also highlights its foundational role in the commercial success and enduring appeal of popular music tracks.\nThe stability of tempo in popular music could be attributed to its deep connection with human locomotion and natural rhythms, such as walking and heartbeats, which do not change significantly over time. Moreover, the danceability of a track, which is highly influenced by its tempo, plays a crucial role in listener engagement—tracks that deviate too far from the tempo norms may not resonate as well with a broad audience. The stability of tempo in popular music could be attributed to its deep connection with human locomotion and natural rhythms, such as walking and heartbeats, which do not change significantly over time. Moreover, the danceability of a track, which is highly influenced by its tempo, plays a crucial role in listener engagement—tracks that deviate too far from the tempo norms may not resonate as well with a broad audience.\nFuture research might explore if this stability holds true across other musical elements or delve deeper into how psychological and physiological responses to tempo contribute to the staying power of certain beats per minute in popular music. This ongoing investigation into the elements of music that transcend temporal and cultural shifts is essential for artists, producers, and industry analysts aiming to craft enduring and appealing musical works!\nThank you for visiting!"
  }
]